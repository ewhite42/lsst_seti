{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8855fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import necessary modules\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cd import CD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.kde import KDE\n",
    "from pyod.models.loci import LOCI\n",
    "from pyod.models.pca import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a620d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in the data, and establish some definitions\n",
    "infile_name = '/home/ellie/research/lsst/LSST_sim.csv'\n",
    "df_initial = pd.read_csv(infile_name)\n",
    "\n",
    "## initialize name of file that the GMM is saved to\n",
    "gmm_fname = \"/home/ellie/research/lsst/gmm.pkl\"\n",
    "\n",
    "## set a value for the percentage of outliers, aka the contamination\n",
    "## (This choice was arbitrary, should probably be tweaked)\n",
    "contamination = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1254e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05494381 0.90483069 0.73278017 ... 0.12610062 0.5413601  0.06213448]\n",
      " [0.05494381 0.90483069 0.73278017 ... 0.12610062 0.53845063 0.06062557]\n",
      " [0.05494381 0.90483069 0.73278017 ... 0.12610062 0.55504017 0.06109883]\n",
      " ...\n",
      " [0.07300705 0.90026414 0.74741902 ... 0.07891649 0.53010546 0.06423747]\n",
      " [0.07300705 0.90026414 0.74741902 ... 0.07891649 0.53953043 0.05520661]\n",
      " [0.07300705 0.90026414 0.74741902 ... 0.07891649 0.53010655 0.06423745]]\n",
      "[0.05494381 0.90483069 0.73278017 0.17357213 0.12610062 0.5413601\n",
      " 0.06213448]\n"
     ]
    }
   ],
   "source": [
    "# select fields of interest\n",
    "subspace = [\"a*\", \"i-z\", \"a\", \"sini\", \"e\", \"v-vk\", \"r\"]\n",
    "df = df_initial[subspace]\n",
    "df = df.dropna()\n",
    "\n",
    "# normalize the data so that values fall in a range from 0-1\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.to_numpy())\n",
    "norm_data = scaler.fit_transform(df.to_numpy()) ## note \"norm_data\" is the same as X in Brian's code\n",
    "\n",
    "#print(norm_data)\n",
    "#print(norm_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6941c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the previously-saved Gaussian mixture model:\n",
    "gmm = joblib.load(gmm_fname)\n",
    "\n",
    "# predict the labels for the data samples in X using the trained model \n",
    "#(need to understand this part better) -MEW\n",
    "labels = gmm.predict(norm_data)\n",
    "\n",
    "## add labels to the pandas dataframe as a new column -MEW\n",
    "df[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ceb2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              a*       i-z         a      sini         e      v-vk         r\n",
      "109248  0.090100 -0.062071  1.888813  0.398239  0.087706  0.000009  1.873713\n",
      "182701  0.085854 -0.066548  2.684560  0.068681  0.225277  0.000009  2.860738\n",
      "408882  0.125065 -0.041721  2.892423  0.231767  0.060799  0.000008  3.057419\n",
      "220097  0.103178 -0.055671  2.347273  0.086732  0.143675  0.000008  2.328561\n",
      "275050 -0.106551  0.064984  2.628937  0.188710  0.131200  0.000003  2.963394\n",
      "...          ...       ...       ...       ...       ...       ...       ...\n",
      "72277   0.092759 -0.056627  2.367557  0.080546  0.143822  0.000011  2.213702\n",
      "428072  0.096613 -0.032858  3.204422  0.157824  0.067351  0.000006  3.004406\n",
      "3117    0.106546 -0.041149  2.572446  0.135607  0.041630  0.000006  2.488952\n",
      "343581  0.095042 -0.058189  2.565701  0.111044  0.298417  0.000022  3.138079\n",
      "66661  -0.093855  0.011141  2.699426  0.078290  0.071763  0.000010  2.868295\n",
      "\n",
      "[150000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "## split the data into training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[\"a*\", \"i-z\", \"a\", \"sini\", \"e\", \"v-vk\", \"r\"]], \n",
    "    df[\"labels\"], #is it ok to use the labels determined by the GMM here? \n",
    "    test_size=.3,\n",
    "    #random_state=42,\n",
    "    stratify=df[\"labels\"], #not sure this is right? \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ea69ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350000,)\n"
     ]
    }
   ],
   "source": [
    "## Try K nearest neighbors (KNN) first...note this bit of code is \n",
    "## directly borrowed from https://pyod.readthedocs.io/en/latest/example.html\n",
    "\n",
    "# train kNN detector\n",
    "clf_name = 'KNN'\n",
    "clf = KNN()\n",
    "clf.fit(X_train)\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "y_train_pred = clf.labels_ # binary labels (0: inliers, 1: outliers)\n",
    "y_train_scores = clf.decision_scores_ # raw outlier scores\n",
    "print(y_train_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2400f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000,)\n"
     ]
    }
   ],
   "source": [
    "# get the prediction on the test data\n",
    "y_test_pred = clf.predict(X_test) # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test) # outlier scores\n",
    "print(y_test_scores.shape)\n",
    "\n",
    "# it is possible to get the prediction confidence as well\n",
    "y_test_pred, y_test_pred_confidence = clf.predict(X_test, return_confidence=True) # outlier labels (0 or 1) and confidence in the range of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7925f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
