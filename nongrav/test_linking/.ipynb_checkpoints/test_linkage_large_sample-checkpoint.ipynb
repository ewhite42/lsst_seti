{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e474e-150b-4fa4-b2f7-305a0f5f5a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this notebook, we will attempt to find the magnitude of nongravitational \n",
    "## acceleration for which heliolinc and link_purify will no longer recognize \n",
    "## a given object as a single body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78bee4bb-5df1-4724-b144-24821ffa1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, import the necessary modules\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import subprocess\n",
    "import sorcha\n",
    "from astroquery.jplhorizons import Horizons\n",
    "from astroquery.jplsbdb import SBDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542ca493-c2bc-47ca-9bdb-c8ac51e5e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define our filepaths and filename stems\n",
    "\n",
    "## filepath for sorcha input and output files\n",
    "sfpath = \"/home/ellie/research/lsst/sorcha_output/2000_obj/\"\n",
    "\n",
    "## filename stems for the orbit files and other files\n",
    "fname_orb = \"2000_obj_orb\"\n",
    "fname_stem = \"2000_obj\"\n",
    "\n",
    "## object ID\n",
    "obj_id = \"2000_obj\"\n",
    "\n",
    "## location of Sorcha config file\n",
    "config_fpath = \"Rubin_full_footprint.ini\"\n",
    "\n",
    "## location of pointing database file for Sorcha\n",
    "pointing_db_path = \"/home/ellie/src/sorcha/sorcha/demo/baseline_v2.0_1yr.db\"\n",
    "\n",
    "## location of Earth location file for HelioLinC\n",
    "earth1day_path = '/home/ellie/research/lsst/heliolinc_files/Earth1day2020s_02a.csv'\n",
    "\n",
    "## location of ObsCodes file for HelioLinC\n",
    "obscodes_path = '/home/ellie/research/lsst/heliolinc_files/ObsCodes.html'\n",
    "\n",
    "## location of colformat file for HelioLinC\n",
    "colformat_path = '/home/ellie/research/lsst/heliolinc_files/colformat.txt'\n",
    "\n",
    "## location of hypothesis file for HelioLinC\n",
    "hypo_path = '/home/ellie/research/lsst/sorcha_output/127005pratchett_new/hihyp00b_mb.txt'\n",
    "\n",
    "## location of kep2cart.py program\n",
    "k2c_path = '/home/ellie/research/lsst/lsst_seti/nongrav/sorcha_ng'\n",
    "\n",
    "## import the kep2cart module\n",
    "kep_dir = os.path.abspath(k2c_path)\n",
    "sys.path.insert(0, kep_dir)\n",
    "\n",
    "from kep2cart import kep2cart as k2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f48fdb-a122-420d-9ce3-66b74f75b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, take a sample of objects and create the Kepler orbits file\n",
    "\n",
    "## note -- spectral type, absolute magnitude, and the slope parameter can\n",
    "## be obtained by querying JPL Horizons (H and G can also be obtained from\n",
    "## the MPC)\n",
    "\n",
    "## first, let's load in ../research/lsst/mpcorb_csvs/mpc_extended_complete.csv\n",
    "## filter down to just MBAs, then choose, say, 10,000 objects at random\n",
    "\n",
    "## then, loop through the 10,000 objects to find which ones have a \n",
    "## spectral classification in JPL Horizons\n",
    "\n",
    "## once we have that filtered list, create the orbits file by querying\n",
    "## the osculating orbital elements in JPL Horizons\n",
    "\n",
    "## then, create the Physical Parameters file once I have confirmation of\n",
    "## how to do this from Grigori\n",
    "\n",
    "## note the table in the notebook Grigori sent uses the SMASSI classification system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccae3c16-a69f-4d12-bc75-ed20e7d5816d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4302/1310468857.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/home/ellie/research/lsst/mpcorb_csvs/mpcorb_extended_complete_vel_2sept.csv')\n"
     ]
    }
   ],
   "source": [
    "## read in the MPC file we created awhile back:\n",
    "df = pd.read_csv('/home/ellie/research/lsst/mpcorb_csvs/mpcorb_extended_complete_vel_2sept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "075a0e5a-4ad8-4a57-a2f2-1bdc29e5991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MBAs: 472906\n"
     ]
    }
   ],
   "source": [
    "main_belts = df.loc[df['Orbit_type'] == 'MBA']\n",
    "main_belts = main_belts.reset_index(drop=True)\n",
    "print(\"Number of MBAs: {}\".format(len(main_belts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4abd3638-aced-4639-a7da-9a91a7d098f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select 2000 MBAs at random\n",
    "\n",
    "min_n = 0\n",
    "max_n = len(main_belts)-1\n",
    "length = 2000\n",
    "random.seed(42)\n",
    "\n",
    "indices = [random.randint(min_n, max_n) for n in range(length)]\n",
    "mba_sample = main_belts.loc[indices]\n",
    "mba_sample = mba_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9ccfb2e-3237-4b04-9486-d7c2f799ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have processed 1 asteroids\n",
      "we have processed 11 asteroids\n",
      "we have processed 21 asteroids\n",
      "we have processed 31 asteroids\n",
      "we have processed 41 asteroids\n",
      "we have processed 51 asteroids\n",
      "we have processed 61 asteroids\n",
      "we have processed 71 asteroids\n",
      "we have processed 81 asteroids\n",
      "we have processed 91 asteroids\n",
      "we have processed 101 asteroids\n",
      "we have processed 111 asteroids\n",
      "we have processed 121 asteroids\n",
      "we have processed 131 asteroids\n",
      "we have processed 141 asteroids\n",
      "we have processed 151 asteroids\n",
      "we have processed 161 asteroids\n",
      "we have processed 171 asteroids\n",
      "we have processed 181 asteroids\n",
      "we have processed 191 asteroids\n",
      "we have processed 201 asteroids\n",
      "we have processed 211 asteroids\n",
      "we have processed 221 asteroids\n",
      "we have processed 231 asteroids\n",
      "we have processed 241 asteroids\n",
      "we have processed 251 asteroids\n",
      "we have processed 261 asteroids\n",
      "we have processed 271 asteroids\n",
      "we have processed 281 asteroids\n",
      "we have processed 291 asteroids\n",
      "we have processed 301 asteroids\n",
      "we have processed 311 asteroids\n",
      "we have processed 321 asteroids\n",
      "we have processed 331 asteroids\n",
      "we have processed 341 asteroids\n",
      "we have processed 351 asteroids\n",
      "we have processed 361 asteroids\n",
      "we have processed 371 asteroids\n",
      "we have processed 381 asteroids\n",
      "we have processed 391 asteroids\n",
      "we have processed 401 asteroids\n",
      "we have processed 411 asteroids\n",
      "we have processed 421 asteroids\n",
      "we have processed 431 asteroids\n",
      "we have processed 441 asteroids\n",
      "we have processed 451 asteroids\n",
      "we have processed 461 asteroids\n",
      "we have processed 471 asteroids\n",
      "we have processed 481 asteroids\n",
      "we have processed 491 asteroids\n",
      "we have processed 501 asteroids\n",
      "we have processed 511 asteroids\n",
      "we have processed 521 asteroids\n",
      "we have processed 531 asteroids\n",
      "we have processed 541 asteroids\n",
      "we have processed 551 asteroids\n",
      "we have processed 561 asteroids\n",
      "we have processed 571 asteroids\n",
      "we have processed 581 asteroids\n",
      "we have processed 591 asteroids\n",
      "we have processed 601 asteroids\n",
      "we have processed 611 asteroids\n",
      "we have processed 621 asteroids\n",
      "we have processed 631 asteroids\n",
      "we have processed 641 asteroids\n",
      "we have processed 651 asteroids\n",
      "we have processed 661 asteroids\n",
      "we have processed 671 asteroids\n",
      "we have processed 681 asteroids\n",
      "we have processed 691 asteroids\n",
      "we have processed 701 asteroids\n",
      "we have processed 711 asteroids\n",
      "we have processed 721 asteroids\n",
      "we have processed 731 asteroids\n",
      "we have processed 741 asteroids\n",
      "we have processed 751 asteroids\n",
      "we have processed 761 asteroids\n",
      "we have processed 771 asteroids\n",
      "we have processed 781 asteroids\n",
      "we have processed 791 asteroids\n",
      "we have processed 801 asteroids\n",
      "we have processed 811 asteroids\n",
      "we have processed 821 asteroids\n",
      "we have processed 831 asteroids\n",
      "we have processed 841 asteroids\n",
      "we have processed 851 asteroids\n",
      "we have processed 861 asteroids\n",
      "we have processed 871 asteroids\n",
      "we have processed 881 asteroids\n",
      "we have processed 891 asteroids\n",
      "we have processed 901 asteroids\n",
      "we have processed 911 asteroids\n",
      "we have processed 921 asteroids\n",
      "we have processed 931 asteroids\n",
      "we have processed 941 asteroids\n",
      "we have processed 951 asteroids\n",
      "we have processed 961 asteroids\n",
      "we have processed 971 asteroids\n",
      "we have processed 981 asteroids\n",
      "we have processed 991 asteroids\n",
      "we have processed 1001 asteroids\n",
      "we have processed 1011 asteroids\n",
      "we have processed 1021 asteroids\n",
      "we have processed 1031 asteroids\n",
      "we have processed 1041 asteroids\n",
      "we have processed 1051 asteroids\n",
      "we have processed 1061 asteroids\n",
      "we have processed 1071 asteroids\n",
      "we have processed 1081 asteroids\n",
      "we have processed 1091 asteroids\n",
      "we have processed 1101 asteroids\n",
      "we have processed 1111 asteroids\n",
      "we have processed 1121 asteroids\n",
      "we have processed 1131 asteroids\n",
      "we have processed 1141 asteroids\n",
      "we have processed 1151 asteroids\n",
      "we have processed 1161 asteroids\n",
      "we have processed 1171 asteroids\n",
      "we have processed 1181 asteroids\n",
      "we have processed 1191 asteroids\n",
      "we have processed 1201 asteroids\n",
      "we have processed 1211 asteroids\n",
      "we have processed 1221 asteroids\n",
      "we have processed 1231 asteroids\n",
      "we have processed 1241 asteroids\n",
      "we have processed 1251 asteroids\n",
      "we have processed 1261 asteroids\n",
      "we have processed 1271 asteroids\n",
      "we have processed 1281 asteroids\n",
      "we have processed 1291 asteroids\n",
      "we have processed 1301 asteroids\n",
      "we have processed 1311 asteroids\n",
      "we have processed 1321 asteroids\n",
      "we have processed 1331 asteroids\n",
      "we have processed 1341 asteroids\n",
      "we have processed 1351 asteroids\n",
      "we have processed 1361 asteroids\n",
      "we have processed 1371 asteroids\n",
      "we have processed 1381 asteroids\n",
      "we have processed 1391 asteroids\n",
      "we have processed 1401 asteroids\n",
      "we have processed 1411 asteroids\n",
      "we have processed 1421 asteroids\n",
      "we have processed 1431 asteroids\n",
      "we have processed 1441 asteroids\n",
      "we have processed 1451 asteroids\n",
      "we have processed 1461 asteroids\n",
      "we have processed 1471 asteroids\n",
      "we have processed 1481 asteroids\n",
      "we have processed 1491 asteroids\n",
      "we have processed 1501 asteroids\n",
      "we have processed 1511 asteroids\n",
      "we have processed 1521 asteroids\n",
      "we have processed 1531 asteroids\n",
      "we have processed 1541 asteroids\n",
      "we have processed 1551 asteroids\n",
      "we have processed 1561 asteroids\n",
      "we have processed 1571 asteroids\n",
      "we have processed 1581 asteroids\n",
      "we have processed 1591 asteroids\n",
      "we have processed 1601 asteroids\n",
      "we have processed 1611 asteroids\n",
      "we have processed 1621 asteroids\n",
      "we have processed 1631 asteroids\n",
      "we have processed 1641 asteroids\n",
      "we have processed 1651 asteroids\n",
      "we have processed 1661 asteroids\n",
      "we have processed 1671 asteroids\n",
      "we have processed 1681 asteroids\n",
      "we have processed 1691 asteroids\n",
      "we have processed 1701 asteroids\n",
      "we have processed 1711 asteroids\n",
      "we have processed 1721 asteroids\n",
      "we have processed 1731 asteroids\n",
      "we have processed 1741 asteroids\n",
      "we have processed 1751 asteroids\n",
      "we have processed 1761 asteroids\n",
      "we have processed 1771 asteroids\n",
      "we have processed 1781 asteroids\n",
      "we have processed 1791 asteroids\n",
      "we have processed 1801 asteroids\n",
      "we have processed 1811 asteroids\n",
      "we have processed 1821 asteroids\n",
      "we have processed 1831 asteroids\n",
      "we have processed 1841 asteroids\n",
      "we have processed 1851 asteroids\n",
      "we have processed 1861 asteroids\n",
      "we have processed 1871 asteroids\n",
      "we have processed 1881 asteroids\n",
      "we have processed 1891 asteroids\n",
      "we have processed 1901 asteroids\n",
      "we have processed 1911 asteroids\n",
      "we have processed 1921 asteroids\n",
      "we have processed 1931 asteroids\n",
      "we have processed 1941 asteroids\n",
      "we have processed 1951 asteroids\n",
      "we have processed 1961 asteroids\n",
      "we have processed 1971 asteroids\n",
      "we have processed 1981 asteroids\n",
      "we have processed 1991 asteroids\n",
      "    ObjID FORMAT         a         e        inc        node     argPeri  \\\n",
      "0  362629    KEP  2.782830  0.229579  12.558258  189.206597  281.695321   \n",
      "1   71515    KEP  2.912152  0.113003  10.192582  172.992805  269.085931   \n",
      "2   24186    KEP  2.342662  0.193642   4.899593   45.103643    3.821532   \n",
      "3  419440    KEP  3.074688  0.203372   3.674556  116.684402   72.544293   \n",
      "4  161190    KEP  3.128746  0.229526  14.638430  356.895362   41.568813   \n",
      "\n",
      "           ma  epochMJD_TDB  \n",
      "0  164.072722       62010.0  \n",
      "1  307.924223       62010.0  \n",
      "2  357.028417       62010.0  \n",
      "3  140.724550       62010.0  \n",
      "4  245.138371       62010.0  \n"
     ]
    }
   ],
   "source": [
    "## create a Keplerian orbits file for all of these objects...\n",
    "\n",
    "## use MJD 62010.00 as our start date for querying the osculating elements\n",
    "start_mjd = 62010.00\n",
    "start_jd = start_mjd+2400000.5\n",
    "\n",
    "ids = []\n",
    "a = []\n",
    "e = []\n",
    "inc = []\n",
    "node = []\n",
    "arg_peri = []\n",
    "ma = []\n",
    "\n",
    "for i in range(len(mba_sample)):\n",
    "    obj = Horizons(id=mba_sample['Principle_desig'][i], location='500@10',epochs=start_jd)\n",
    "    el = obj.elements()\n",
    "    #print(el['a'][0])\n",
    "\n",
    "    id = el['targetname'][0].split()[0]    \n",
    "    ids.append(id)\n",
    "    \n",
    "    a.append(el['a'][0])\n",
    "    e.append(el['e'][0])\n",
    "    inc.append(el['incl'][0])\n",
    "    node.append(el['Omega'][0])\n",
    "    arg_peri.append(el['w'][0])\n",
    "    ma.append(el['M'][0])\n",
    "\n",
    "    #print(f\"we have processed {i+1} asteroids\")\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f\"we have processed {i+1} asteroids\")\n",
    "\n",
    "df_mba = pd.DataFrame()\n",
    "\n",
    "df_mba['ObjID'] = ids\n",
    "df_mba['FORMAT'] = ['KEP']*len(mba_sample)\n",
    "df_mba['a'] = a\n",
    "df_mba['e'] = e\n",
    "df_mba['inc'] = inc \n",
    "df_mba['node'] = node\n",
    "df_mba['argPeri'] = arg_peri\n",
    "df_mba['ma'] = ma\n",
    "df_mba['epochMJD_TDB'] = [start_mjd]*len(mba_sample)\n",
    "\n",
    "print(df_mba.head(5))\n",
    "df_mba.to_csv('2000_obj_orb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae4aa9dc-fcaa-4685-85aa-b9c1257339fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       281.695321\n",
      "1       269.085931\n",
      "2         3.821532\n",
      "3        72.544293\n",
      "4        41.568813\n",
      "           ...    \n",
      "1995    326.541368\n",
      "1996    233.859828\n",
      "1997    178.422434\n",
      "1998     83.208723\n",
      "1999     77.947243\n",
      "Name: argPeri, Length: 2000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_mba['argPeri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86860461-8604-4379-af9f-8ad848852317",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert data from strings to floats\n",
    "\n",
    "df_mba['a'] = pd.to_numeric(df_mba['a'], errors='coerce')\n",
    "df_mba['e'] = pd.to_numeric(df_mba['e'], errors='coerce')\n",
    "df_mba['inc'] = pd.to_numeric(df_mba['inc'], errors='coerce')\n",
    "df_mba['node'] = pd.to_numeric(df_mba['node'], errors='coerce')\n",
    "df_mba['argPeri'] = pd.to_numeric(df_mba['argPeri'], errors='coerce')\n",
    "df_mba['ma'] = pd.to_numeric(df_mba['ma'], errors='coerce')\n",
    "df_mba['epochMJD_TDB'] = pd.to_numeric(df_mba['epochMJD_TDB'], errors='coerce')\n",
    "\n",
    "df_mba.to_csv('2000_obj_orb_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "229f59d6-2947-48dd-b755-800186d75f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Cartesian orbits file /home/ellie/research/lsst/sorcha_output/2000_obj/2000_obj_orb_cart.csv written.\n"
     ]
    }
   ],
   "source": [
    "## create Sorcha inputs\n",
    "\n",
    "k2c(\"{0}.csv\".format(fname_orb), \"{0}{1}_cart.csv\".format(sfpath, fname_orb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "131acc63-e1cb-4f0f-95d5-66a80ea50db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the nongravitational orbits files\n",
    "nongravs = np.logspace(start=-12, stop=3, num=16, base=10) \n",
    "\n",
    "df = pd.read_csv(\"{0}{1}_cart.csv\".format(sfpath, fname_orb))\n",
    "df['FORMAT'] = 'NONGRAV'\n",
    "df['a1'] = [0.0]*len(df)\n",
    "df['a2'] = [0.0]*len(df)\n",
    "df['a3'] = [0.0]*len(df)\n",
    "df['model'] = 'ASTEROID'\n",
    "epoch = df.pop('epochMJD_TDB')\n",
    "df.insert(12, 'epochMJD_TDB', epoch)\n",
    "\n",
    "orb_files = [\"{0}{1}_cart.csv\".format(sfpath, fname_orb)]\n",
    "\n",
    "for i in range(len(nongravs)):\n",
    "    df1 = df.copy()\n",
    "    df1['a1'] = [nongravs[i]]*len(df)\n",
    "    df1_fname = \"{0}{1}_ng_a1_{2}.csv\".format(sfpath, fname_orb, np.log10(nongravs[i]))\n",
    "    df1.to_csv(df1_fname, index=False)\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2['a2'] = [nongravs[i]]*len(df)\n",
    "    df2_fname = \"{0}{1}_ng_a2_{2}.csv\".format(sfpath, fname_orb, np.log10(nongravs[i]))\n",
    "    df2.to_csv(df2_fname, index=False)\n",
    "\n",
    "    df3 = df.copy()\n",
    "    df3['a3'] = [nongravs[i]]*len(df)\n",
    "    df3_fname = \"{0}{1}_ng_a3_{2}.csv\".format(sfpath, fname_orb, np.log10(nongravs[i]))\n",
    "    df3.to_csv(df3_fname, index=False)\n",
    "\n",
    "    orb_files.append(df1_fname)\n",
    "    orb_files.append(df2_fname)\n",
    "    orb_files.append(df3_fname)  \n",
    "\n",
    "df_orbfiles = pd.DataFrame()\n",
    "df_orbfiles['orb_files'] = orb_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d3b2b51-07d1-479b-9135-a6bc2a307f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   filter         D         R       TNO        Cg        Sv         B  \\\n",
      "0  lsst_u  1.859943  2.152559  2.483564  1.884415  2.020381  1.649919   \n",
      "1  lsst_g  0.569196  0.684244  0.903612  0.533468  0.636982  0.453676   \n",
      "2  lsst_r  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3  lsst_i -0.215898 -0.173417 -0.390387 -0.111948 -0.227216 -0.089597   \n",
      "4  lsst_z -0.300861  0.025841 -0.592196 -0.109281 -0.164652 -0.065739   \n",
      "\n",
      "          V        Sr       Cgh  ...         K        Xk         S        Cb  \\\n",
      "0  2.178326  2.124353  1.869496  ...  1.929924  1.761290  2.076456  1.563729   \n",
      "1  0.686681  0.646236  0.508681  ...  0.584152  0.513720  0.645386  0.430048   \n",
      "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "3 -0.152801 -0.176642 -0.109340  ... -0.171675 -0.153968 -0.195236 -0.126599   \n",
      "4  0.159448 -0.075856 -0.138538  ... -0.149098 -0.172526 -0.139287 -0.146284   \n",
      "\n",
      "         Xc         O         C         A        Sq  Unnamed: 22  \n",
      "0  1.764798  1.842147  1.684176  2.460320  2.055801          NaN  \n",
      "1  0.509379  0.524702  0.469244  0.784019  0.628828          NaN  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000          NaN  \n",
      "3 -0.156182 -0.084569 -0.116649 -0.221959 -0.166113          NaN  \n",
      "4 -0.185811  0.142535 -0.121954 -0.142965 -0.082798          NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (2000)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m df_phy = pd.DataFrame()\n\u001b[32m     10\u001b[39m df_phy[\u001b[33m'\u001b[39m\u001b[33mObjID\u001b[39m\u001b[33m'\u001b[39m] = df_mba[\u001b[33m'\u001b[39m\u001b[33mObjID\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mdf_phy\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mH_r\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = [\u001b[32m5.63\u001b[39m]\n\u001b[32m     12\u001b[39m df_phy[\u001b[33m'\u001b[39m\u001b[33mu-r\u001b[39m\u001b[33m'\u001b[39m] = [\u001b[32m2.55\u001b[39m]\n\u001b[32m     13\u001b[39m df_phy[\u001b[33m'\u001b[39m\u001b[33mg-r\u001b[39m\u001b[33m'\u001b[39m] = [\u001b[32m0.92\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/anaconda3/envs/sorcha_dev/lib/python3.13/site-packages/pandas/core/frame.py:4322\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4319\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4321\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4322\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/anaconda3/envs/sorcha_dev/lib/python3.13/site-packages/pandas/core/frame.py:4535\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4526\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4527\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4528\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4533\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4534\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4535\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4538\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4539\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4540\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4541\u001b[39m     ):\n\u001b[32m   4542\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4543\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/anaconda3/envs/sorcha_dev/lib/python3.13/site-packages/pandas/core/frame.py:5288\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5288\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5289\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5291\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5292\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5295\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5296\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/anaconda3/envs/sorcha_dev/lib/python3.13/site-packages/pandas/core/common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (1) does not match length of index (2000)"
     ]
    }
   ],
   "source": [
    "## generate Physical Parameters file using placeholder values\n",
    "## (these are not the correct values, need to fix)\n",
    "\n",
    "df_spec = pd.read_csv('spectral_type_lut.csv')\n",
    "u_mag = df_spec['C'][0]\n",
    "g_mag = df_spec['C'][1]\n",
    "r_mag = df_spec['C'][2]\n",
    "i_mag = df_spec['C'][3]\n",
    "z_mag = df_spec['C'][4]\n",
    "y_mag = df_spec['C'][5]\n",
    "\n",
    "#print(df_spec.head(5))\n",
    "\n",
    "df_phy = pd.DataFrame()\n",
    "df_phy['ObjID'] = df_mba['ObjID']\n",
    "df_phy['H_r'] = [5.63]\n",
    "df_phy['u-r'] = [u_mag-r_mag]*len(df_mba)\n",
    "df_phy['g-r'] = [g_mag-r_mag]\n",
    "df_phy['i-r'] = [i_mag-r_mag]\n",
    "df_phy['z-r'] = [z_mag-r_mag]\n",
    "df_phy['y-r'] = [y_mag-r_mag]\n",
    "df_phy['GS'] = [0.15]\n",
    "\n",
    "df_phy.to_csv(\"{0}{1}_phy.csv\".format(sfpath, fname_stem), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d9de35-5539-4c97-929f-289abab0a38c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mba_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## now, filter down this sample so that it only includes MBAs\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m## with SMASSI spectral classes identified: \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m mba_names = \u001b[43mmba_sample\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mPrinciple_desig\u001b[39m\u001b[33m'\u001b[39m].to_numpy()\n\u001b[32m      5\u001b[39m indices_specb = []\n\u001b[32m      7\u001b[39m \u001b[33;03m'''for i in range(len(mba_names)):\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    ast_name = mba_names[i]\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    obj = SBDB.query(ast_name, phys=True) \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[33;03mprint(len(indices_specb))'''\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'mba_sample' is not defined"
     ]
    }
   ],
   "source": [
    "## code to check if a given asteroid has a specified spectral class\n",
    "## may not actually use this\n",
    "\n",
    "mba_names = mba_sample['Principle_desig'].to_numpy()\n",
    "indices_specb = []\n",
    "\n",
    "for i in range(len(mba_names)):\n",
    "    ast_name = mba_names[i]\n",
    "    obj = SBDB.query(ast_name, phys=True) \n",
    "\n",
    "    try:\n",
    "        spec_B = obj['phys_par']['spec_B']\n",
    "        indices_specb.append(i)\n",
    "        print(f\"{mba_names[i]} has a spectral type, adding to list: {i+1}/{len(mba_names)}\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"{mba_names[i]} does not have a spectral type, skipping\")\n",
    "\n",
    "print(len(indices_specb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b4cb329-2bed-418f-9808-f3a430ca53d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n"
     ]
    }
   ],
   "source": [
    "print(len(indices_specb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
